p1_prompt = """
I am doing research assessing the availability of data and code in published papers. Help me extract the relevant information in the attached paper and provide your best response to the following items in JSON format. Make your best effort to fill in all items in the specified JSON schema.

* authors: Who are the authors of the paper? Provide name, department, institution, country and whether they are corresponding authors. Note that department can be either a department, school, center, division, or branch of an institution, while an institution is the name a higher educational institution, a company, a governmental body, or any other organization.
* topics: What are the topics of the paper? Choose up to two best matching topics from the following list: Aviation, Marine, Freight, Rail, Public Transportation, "Transportation Sustainability and Resillence", Transportation Infrastructure, "Data, Planning and Analysis", "Policy and Organization", "Safety and Operation". Return a list.
* keywords: What are the keywords of the paper?
* is_data_needed_for_reproduce: If the paper used data in research, is the data needed for reproducing the results by external researchers? Return a boolean. Note that this should be true only if the paper used data for research and the data is necessary for reproducing the results by external researchers.
* is_data_publically_available: According to the content of the paper, is the data used in the paper publically available? Return a boolean.
* is_code_publically_available: According to the content of the paper, is the code for the paper publically available? Return a boolean.
* software: What software is used in the research of the paper? Include specific software, packages, and/or programming language used, but not generic methods such as numeric simulation or Linear Programming Solvers; For packages, provide the official name of the package, for example, "networkX", not "NetworkX Python library". Return a list, an empty list if not applicable.
* code_link: Is there a link (or links) to the code provided in the paper? Return a list, an empty list for none.
* data_link: Is there a link (or links) to the data provided in the paper? Return a list, an empty list for none.
* reason_code_unavailable: If the code is not publically available, what is the reason the author(s) provided? Return 'null' if not applicable.
* reason_data_unavailable: If the data is not publicly available, what is the reason the author(s) provided? Return 'null' if not applicable.
* data_availability_section: Does the paper include a data availability section? Return a boolean.
* data_source: How was the data used in the paper derived? Choose one of the following options:
- **collected**: Data obtained directly from real-world sources such as sensors, experiments, surveys, or other observational methods; or data and information from people.
- **synthetic**: Data entirely generated by simulations, synthetic datasets, or artificial models without real-world inputs.
- **both**: A combination of real-world collected data and synthetic data, either through augmentation, simulation tuning, or a hybrid approach.
- **neither**: The study does not use data, or if the paper references datasets, experiments, or studies for conceptual discussion but does not process or analyze the data, classify it as "neither."
* data_source_reasoning: Provide supporting evidence from the paper, such as descriptions of datasets, methodology sections, or figures that indicate how the data was generated. If "Both" is the answer, explain in what way real-world and synthetic data were integrated.
"""

git_repo_prompt = """
If the input string is a github repository or a link to a file/directory in a git repository, parse and get the URL of the repository for cloning; if not, return an empty string.

For example, 
Input URL = "https://gitlab.com/gitlab-org/gitlab", return = "https://gitlab.com/gitlab-org/gitlab"
Input URL = "https://github.com/asu-trans-ai-lab/Path4GMNS/tree/master/dataset", return = "https://github.com/asu-trans-ai-lab/Path4GMNS"
Input URL = "https://www.kaggle.com/datasets/usdot/nhtsa-traffic-fatalities", return = ""
"""

p2_prompt = """
Based on the attached screenshot and converted markdown file of {url}, help me extract the relevant information at the URL and provide your best response to the following items in JSON format.

* DOI: {doi}
* code_readme: If the URL contains code, does it include a readme for the code? Return a boolean.
* code_license: If the URL contains code, what is the license under which the code is distributed. Return 'null' if not applicable.
* code_setup: Does the URL include a setup script, such as requirements.txt for Python project? Return a boolean and 'null' if not applicable.
* code_hardware_reqs: What hardware specification is required to run the code? Return a string, 'null' if not applicable
* code_software_reqs: What software is required to run the code? Return a list, 'null' if not applicable

* data_url: Is the URL a link to access (view, download) a dataset or datasets? Return a boolean.
* data_downloadable: If the URL points to a dataset(s), is the dataset(s) downloadable from the URL? Return a boolean.
* data_readme: If the URL points to a dataset(s), does the dataset(s) include a readme? Return a boolean.
* data_dictionary: If the URL points to a dataset(s), does the dataset include a data dictionary? Return a boolean.
* data_license: If the URL points to a dataset(s), what is the license under which the dataset is distributed. Return 'null' if not applicable or unspecified.
"""

data_reproduce = """
I am doing research assessing the availability of data and code in published papers. Help me extract the relevant information in the attached paper and provide your best response to the following items in JSON format. Make your best effort to fill in all items in the specified JSON schema.

* is_data_needed_for_reproduce: If the paper used data in research, is the data needed for reproducing the results (plots, analysis, etc) by external researchers? Return a boolean. Note that this should be true only if the paper used data for research and the data is necessary for reproducing the results by external researchers.
"""

data_source = """
I am doing research assessing the types of data used in published papers. Help me extract the relevant information in the attached paper and provide your best response to the following items in JSON format. Make your best effort to fill in all items in the specified JSON schema.

* data_source: How was this data derived?
- **collected**: Data obtained directly from real-world sources such as sensors, experiments, surveys, or other observational methods; or data and information from people.
- **synthetic**: Data entirely generated by simulations, synthetic datasets, or artificial models without real-world inputs.
- **both**: A combination of real-world collected data and synthetic data, either through augmentation, simulation tuning, or a hybrid approach.
- **neither**: The study does not use data.

* reasoning: Provide supporting evidence from the paper, such as descriptions of datasets, methodology sections, or figures that indicate how the data was generated. If "Both" is the answer, explain in what way real-world and synthetic data were integrated.
"""

software_prompt = """
I am conducting research to assess the technology stack used in published research papers. Your task is to extract detailed and distinct information regarding both software and hardware from the attached paper. Return your response strictly in JSON format following the schema below. Ensure that each item is assigned only to its most appropriate category, avoiding overlaps. For example, if "Ubuntu" is mentioned, classify it under operating_systems rather than software_used; if "PyTorch" appears, list it only under packages_libraries.

The JSON schema is as follows:
{
  "programming_languages": [string],
  "operating_systems": [string],
  "software_used": [string],
  "packages_libraries": [string],
  "hardware_specs": [string]
}

Instructions:
1. programming_languages: List all programming languages used. Return an empty list if none are found.
2. operating_systems: Identify any operating systems mentioned (e.g., Windows, Linux, Ubuntu). These should not be repeated under software_used.
3. software_used: Extract the names of standalone software tools (applications) that were used as part of the research workflow. Do not include operating systems or libraries here.
4. packages_libraries: List libraries, packages, or frameworks (e.g., PyTorch, TensorFlow, scikit-learn) that the authors used during implementation. Ensure that each entry is exclusive to this category.
5. hardware_specs: Extract any hardware specifications mentioned (e.g., GPU models, CPU details, memory configurations, server specs).

If a particular category is not mentioned in the paper, return an empty list for that field. Make your best effort to accurately fill in each field without duplicating or misclassifying entries.
"""
